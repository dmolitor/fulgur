---
title: fulgur
format: gfm
---

The goal of fulgur is to facilitate estimating a variety of linear models on
extremely large (e.g. out-of-core) datasets. fulgur provides a simple but flexible interface,
allowing model specification via formula syntax
(see [formulaic](https://github.com/matthewwardrop/formulaic) for details),
and can fit a variety of linear models including OLS, Ridge, Lasso, Elastic Net, etc.


# Example - airline arrival delays

Below we'll demonstrate fitting an OLS model to predict airline arrival delays
using a large publicly available dataset of US airline on-time performance.

First we'll load the necessary packages.
```{python}
from fulgur.regression import LargeLinearRegressor
import polars as pl
```

## Load data

We'll load the airlines dataset from AWS as a
[lazy DataFrame](https://docs.pola.rs/user-guide/lazy/using/). This dataset has approximately
120 million rows which can be too large to fit into memory on some computers, particularly
when fitting regression models. We will then create split the data into a training and
evaluation set for model assessment.
```{python}
airline = pl.scan_parquet(
    "s3://fulgur-large-regression/airline/",
    storage_options={"skip_signature": "true"}
)
airline = airline.drop("index").with_row_index(offset=1)

# Get train set and an evaluation set
airline_train = airline.head(118000000)
airline_eval = airline.tail(914458)
```

## Query the data

Next we'll design a query to drop rows in our data with missing values and to filter
out cancelled flights.
```{python}
def query_fn(x: pl.LazyFrame):
    return (
        x
        .filter(pl.col("cancelled").ne(1))
        .drop_nulls(["arrival_delay", "departure_delay", "scheduled_elapsed_time"])
        .drop_nans(["arrival_delay", "departure_delay", "scheduled_elapsed_time"])
    )
```

## Fit the model

Finally, we'll train our OLS model. We will predict flights' arrival delays
using departure delays and scheduled elapsed time as predictors.
```{python}
llm = LargeLinearRegressor(
    formula="arrival_delay ~ departure_delay + scheduled_elapsed_time",
    data=airline_train,
    query=query_fn,
    batch_size=10000,
    type="ols",
    learning_rate="invscaling"
)
llm.fit(verbose=False)
```

## Compare to standard OLS

fulgur fits its linear models via
[Stochastic Gradient Descent (SGD)](https://scikit-learn.org/stable/modules/sgd.html).
We'll compare our SGD-based coefficients and Root Mean Squared Error (RMSE)
on the evaluation set to those from a standard OLS model.
```{python}
#| eval: true
#| echo: true
#| code-fold: true

from fulgur.utils import encode_categorical, scale_numeric
import statsmodels.api as sm

def rmse(y_true, y_pred):
    return ((y_true - y_pred) ** 2).mean() ** 0.5

# Construct design matrix
data = llm.query(airline_train) if llm.query else airline_train
stats = llm.stats
data = scale_numeric(data=data, stats=stats)
data = encode_categorical(data=data, formula=llm.formula)
comparison_data = llm.prep(data.collect(), output="numpy")
X = comparison_data.rhs
y = comparison_data.lhs.ravel()

# Fit OLS with statsmodels
results = sm.OLS(y, X, hasconst=True).fit()

print(f"SGD Coefficients: {[round(float(x), 3) for x in llm.model.coef_]}")
print(f"OLS Coefficients: {[round(float(x), 3) for x in results.params]}")

# Compare SGD RMSE to OLS RMSE
pred_data = llm.query(airline_eval) if llm.query else airline_eval
pred_data = scale_numeric(data=pred_data, stats=stats)
pred_data = encode_categorical(data=pred_data, formula=llm.formula)
pred_data = llm.prep(pred_data.collect(), output="numpy")
X_pred = pred_data.rhs
sgd_preds = llm.predict(airline_eval)
ols_preds = results.predict(X_pred)

y_truth = pred_data.lhs.ravel()
sgd_rmse = rmse(y_truth, sgd_preds)
ols_rmse = rmse(y_truth, ols_preds)
print("-----------------------------------------")
print(f"SGD RMSE: {round(float(sgd_rmse), 3)}")
print(f"OLS RMSE: {round(float(ols_rmse), 3)}")
```

We see that our fulgur SGD-based OLS model achieves similar (slightly better) hold-out error
to the standard OLS model while being far more memory and computationally efficient.